{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f816948b",
   "metadata": {},
   "source": [
    "<h1><b>Assignment 1</b></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a77e64",
   "metadata": {},
   "source": [
    "<b>Web scraping</b>\n",
    "<br>In all the following questions, you have to use BeautifulSoup to scrape different websites and collect data as per\n",
    "the requirement of the question.\n",
    "Every answer to the question should be in form of a python function which should take URL as the parameter.\n",
    "Use Jupyter Notebooks to program, upload it on your GitHub and send the link of the Jupyter notebook to your\n",
    "SME.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bead3465",
   "metadata": {},
   "source": [
    "Importing all the required Libraries beforehand below -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82465cff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T17:32:58.744563Z",
     "start_time": "2023-05-28T17:32:57.966496Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as Bs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d289ac88",
   "metadata": {},
   "source": [
    "Function to check the validity of web scraping for the mentioned website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3bcdc38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T17:32:58.760496Z",
     "start_time": "2023-05-28T17:32:58.747497Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_allowed(r):\n",
    "    if r.status_code == 200:\n",
    "        return \"The website allows Data Scraping.\"\n",
    "    else:\n",
    "        return \"The website does not allow Data Scraping.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c0c2bf",
   "metadata": {},
   "source": [
    "<h2>Write a python program to display all the header tags from the following Wikipedia link and make data frame.</h2>\n",
    "<br>Link: \n",
    "<a href=\"wikipedia.org\">Wikipedia</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "405052ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T17:32:59.186190Z",
     "start_time": "2023-05-28T17:32:58.762495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The website allows Data Scraping.\n"
     ]
    }
   ],
   "source": [
    "URL = 'https://www.wikipedia.org/'\n",
    "r = requests.get(URL)\n",
    "print(is_allowed(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44e4daab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T17:32:59.266149Z",
     "start_time": "2023-05-28T17:32:59.188148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Header texts were found!\n"
     ]
    }
   ],
   "source": [
    "#Fetching the soup\n",
    "content = r.text\n",
    "soup = Bs(content, 'html.parser')\n",
    "\n",
    "# Find all the header tags (h1 to h6)\n",
    "header_tags = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])\n",
    "\n",
    "# Extract the text from the header tags\n",
    "try:\n",
    "    header_texts = [tag.text.strip().replace('\\n', ' ') for tag in header_tags]\n",
    "except:\n",
    "    print(\"One or More Header texts were not found!\")\n",
    "else:\n",
    "    print(\"All Header texts were found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af4aad1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T17:32:59.298148Z",
     "start_time": "2023-05-28T17:32:59.268150Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Header</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wikipedia  The Free Encyclopedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 000 000+   articles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100 000+   articles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 000+   articles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 000+   articles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100+   articles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Header\n",
       "0  Wikipedia  The Free Encyclopedia\n",
       "1             1 000 000+   articles\n",
       "2               100 000+   articles\n",
       "3                10 000+   articles\n",
       "4                 1 000+   articles\n",
       "5                   100+   articles"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'Header': header_texts})\n",
    "\n",
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77c0ac2",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d3e712",
   "metadata": {},
   "source": [
    "<h2> Write a python program to display list of respected former presidents of India <br>(i.e. Name, Term of office)\n",
    "from the following links and make data frame: </h2>\n",
    "<br>Link: \n",
    "<a href=\"https://presidentofindia.nic.in/former-presidents.htm\">Former Presidents of India</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55056664",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T17:32:59.486149Z",
     "start_time": "2023-05-28T17:32:59.301149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The website allows Data Scraping.\n"
     ]
    }
   ],
   "source": [
    "URL = 'https://presidentofindia.nic.in/former-presidents.htm'\n",
    "r = requests.get(URL)\n",
    "print(is_allowed(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a4ca070",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T17:32:59.550150Z",
     "start_time": "2023-05-28T17:32:59.489149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Data found!\n"
     ]
    }
   ],
   "source": [
    "#Fetching the soup\n",
    "content = r.text\n",
    "soup = Bs(content, 'html.parser')\n",
    "\n",
    "#Error Variable/s\n",
    "err1 = 0\n",
    "err2 = 0\n",
    "\n",
    "#Name and Age tags are together. Tenure and Website tags are together\n",
    "try:\n",
    "    Name_Age_tags = soup.find_all('h3')\n",
    "except:\n",
    "    print(\"One or More <h3> tags not found!\")\n",
    "\n",
    "\n",
    "try:\n",
    "    Tenure_Website_tags = soup.find_all('p')\n",
    "except:\n",
    "    print(\"One or more <p> tags not found!\")\n",
    "\n",
    "\n",
    "#Lists to store the data\n",
    "Names = []\n",
    "Age = []\n",
    "tenure = []\n",
    "website = []\n",
    "\n",
    "#Extract Names from Name_Age_Tags\n",
    "try:\n",
    "    Names = [tag.text.split('(')[0].strip() for tag in Name_Age_tags]\n",
    "except:\n",
    "    print(\"Unable to append names into the list!\")\n",
    "else: \n",
    "    err1+=1\n",
    "    \n",
    "#Extract Age from Name_Age_Tags\n",
    "try:\n",
    "    Age = [tag.text.split('(')[1].replace(')', '').strip() for tag in Name_Age_tags]\n",
    "except:\n",
    "    print(\"Unable to append names into the list!\")\n",
    "else: \n",
    "    err1+=1\n",
    "    \n",
    "try:\n",
    "#Extract Tenure and Website from Tenure_Website_tags\n",
    "    for i in range(0, len(Tenure_Website_tags)):\n",
    "        if Tenure_Website_tags[i].find_all('span', class_ = \"terms\") and Tenure_Website_tags[i+1].find_all('a'):\n",
    "            tenure.append(Tenure_Website_tags[i].span.next_sibling) \n",
    "            website.append(Tenure_Website_tags[i+1].a['href'])\n",
    "\n",
    "        elif Tenure_Website_tags[i].find_all('span', class_ = \"terms\") and not Tenure_Website_tags[i+1].find_all('a'):\n",
    "            tenure.append(Tenure_Website_tags[i].span.next_sibling) \n",
    "            website.append('Not available')\n",
    "\n",
    "        else:\n",
    "            i = i+1\n",
    "except Exception as error:\n",
    "    print(\"Error in appending Tenure or Websites:\", error)\n",
    "    \n",
    "else:\n",
    "    err1+=1\n",
    "\n",
    "    \n",
    "if err1 == 3:\n",
    "    print(\"All Data found!\")\n",
    "else:\n",
    "    print(\"Something went wrong!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae743a55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T17:32:59.583151Z",
     "start_time": "2023-05-28T17:32:59.554150Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Ram Nath Kovind</td>\n",
       "      <td>birth - 1945</td>\n",
       "      <td>25 July, 2017 to 25 July, 2022</td>\n",
       "      <td>https://ramnathkovind.nic.in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shri Pranab Mukherjee</td>\n",
       "      <td>1935-2020</td>\n",
       "      <td>25 July, 2012 to 25 July, 2017</td>\n",
       "      <td>http://pranabmukherjee.nic.in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smt Pratibha Devisingh Patil</td>\n",
       "      <td>birth - 1934</td>\n",
       "      <td>25 July, 2007 to 25 July, 2012</td>\n",
       "      <td>http://pratibhapatil.nic.in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam</td>\n",
       "      <td>1931-2015</td>\n",
       "      <td>25 July, 2002 to 25 July, 2007</td>\n",
       "      <td>http://abdulkalam.nic.in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shri K. R. Narayanan</td>\n",
       "      <td>1920 - 2005</td>\n",
       "      <td>25 July, 1997 to 25 July, 2002</td>\n",
       "      <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dr Shankar Dayal Sharma</td>\n",
       "      <td>1918-1999</td>\n",
       "      <td>25 July, 1992 to 25 July, 1997</td>\n",
       "      <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shri R Venkataraman</td>\n",
       "      <td>1910-2009</td>\n",
       "      <td>25 July, 1987 to 25 July, 1992</td>\n",
       "      <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Giani Zail Singh</td>\n",
       "      <td>1916-1994</td>\n",
       "      <td>25 July, 1982 to 25 July, 1987</td>\n",
       "      <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy</td>\n",
       "      <td>1913-1996</td>\n",
       "      <td>25 July, 1977 to 25 July, 1982</td>\n",
       "      <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed</td>\n",
       "      <td>1905-1977</td>\n",
       "      <td>24 August, 1974 to 11 February, 1977</td>\n",
       "      <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shri Varahagiri Venkata Giri</td>\n",
       "      <td>1894-1980</td>\n",
       "      <td>3 May, 1969 to 20 July, 1969 and 24 August, 1...</td>\n",
       "      <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dr. Zakir Husain</td>\n",
       "      <td>1897-1969</td>\n",
       "      <td>13 May, 1967 to 3 May, 1969</td>\n",
       "      <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan</td>\n",
       "      <td>1888-1975</td>\n",
       "      <td>13 May, 1962 to 13 May, 1967</td>\n",
       "      <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dr. Rajendra Prasad</td>\n",
       "      <td>1884-1963</td>\n",
       "      <td>26 January, 1950 to 13 May, 1962</td>\n",
       "      <td>Not available</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Name           Age  \\\n",
       "0           Shri Ram Nath Kovind  birth - 1945   \n",
       "1          Shri Pranab Mukherjee     1935-2020   \n",
       "2   Smt Pratibha Devisingh Patil  birth - 1934   \n",
       "3         DR. A.P.J. Abdul Kalam     1931-2015   \n",
       "4           Shri K. R. Narayanan   1920 - 2005   \n",
       "5        Dr Shankar Dayal Sharma     1918-1999   \n",
       "6            Shri R Venkataraman     1910-2009   \n",
       "7               Giani Zail Singh     1916-1994   \n",
       "8      Shri Neelam Sanjiva Reddy     1913-1996   \n",
       "9       Dr. Fakhruddin Ali Ahmed     1905-1977   \n",
       "10  Shri Varahagiri Venkata Giri     1894-1980   \n",
       "11              Dr. Zakir Husain     1897-1969   \n",
       "12  Dr. Sarvepalli Radhakrishnan     1888-1975   \n",
       "13           Dr. Rajendra Prasad     1884-1963   \n",
       "\n",
       "                                               Tenure  \\\n",
       "0                     25 July, 2017 to 25 July, 2022    \n",
       "1                     25 July, 2012 to 25 July, 2017    \n",
       "2                     25 July, 2007 to 25 July, 2012    \n",
       "3                     25 July, 2002 to 25 July, 2007    \n",
       "4                     25 July, 1997 to 25 July, 2002    \n",
       "5                     25 July, 1992 to 25 July, 1997    \n",
       "6                     25 July, 1987 to 25 July, 1992    \n",
       "7                     25 July, 1982 to 25 July, 1987    \n",
       "8                     25 July, 1977 to 25 July, 1982    \n",
       "9                24 August, 1974 to 11 February, 1977   \n",
       "10   3 May, 1969 to 20 July, 1969 and 24 August, 1...   \n",
       "11                        13 May, 1967 to 3 May, 1969   \n",
       "12                       13 May, 1962 to 13 May, 1967   \n",
       "13                   26 January, 1950 to 13 May, 1962   \n",
       "\n",
       "                          Website  \n",
       "0    https://ramnathkovind.nic.in  \n",
       "1   http://pranabmukherjee.nic.in  \n",
       "2     http://pratibhapatil.nic.in  \n",
       "3        http://abdulkalam.nic.in  \n",
       "4                   Not available  \n",
       "5                   Not available  \n",
       "6                   Not available  \n",
       "7                   Not available  \n",
       "8                   Not available  \n",
       "9                   Not available  \n",
       "10                  Not available  \n",
       "11                  Not available  \n",
       "12                  Not available  \n",
       "13                  Not available  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Column Names\n",
    "col = ['Name', 'Age', 'Tenure', 'Website']\n",
    "\n",
    "#Data\n",
    "data = list(zip(Names, Age, tenure, website))\n",
    "\n",
    "#Creating the Dataframe\n",
    "df = pd.DataFrame(data= data, columns = col)\n",
    "\n",
    "#Displaying the Dataframe\n",
    "(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff67f29b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T11:20:35.346776Z",
     "start_time": "2023-05-28T11:20:35.337758Z"
    }
   },
   "source": [
    "<h2> Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame -</h2>\n",
    "\n",
    "<h3> Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.</h3>\n",
    "<br>Link:\n",
    "<a href=\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\">ODI Team Rankings</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5a3105e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T17:32:59.740150Z",
     "start_time": "2023-05-28T17:32:59.588150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The website allows Data Scraping.\n"
     ]
    }
   ],
   "source": [
    "URL = \"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\"\n",
    "r = requests.get(URL)\n",
    "print(is_allowed(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b49ac4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T17:32:59.852148Z",
     "start_time": "2023-05-28T17:32:59.742150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data found!\n"
     ]
    }
   ],
   "source": [
    "#Fetching the soup\n",
    "content = r.text\n",
    "soup = Bs(content, 'html.parser')\n",
    "table_soup = soup.find('table')\n",
    "\n",
    "#Lists to store the data\n",
    "Names = []\n",
    "Matches = []\n",
    "Points = []\n",
    "Ratings = []\n",
    "\n",
    "#Error Variable/s\n",
    "err = 0\n",
    "\n",
    "try:\n",
    "    table_soup_Name_Tags = table_soup.find_all('span', class_=\"u-hide-phablet\")\n",
    "    table_soup_Matches_Points_Tags = table_soup.find_all('td', class_=\"table-body__cell u-center-text\")\n",
    "    table_soup_Rating_Tags = table_soup.find_all('td', class_=\"table-body__cell u-text-right rating\")\n",
    "except Exception as error:\n",
    "    print(\"Following error occured when trying to use .find_all() function for retrieving Name/Tags/Matches/Ratings:\")\n",
    "    print(error)\n",
    "\n",
    "try:\n",
    "    Names.append(table_soup.find('span', class_=\"u-hide-phablet\").text)\n",
    "    Matches.append(table_soup.find('td', class_=\"rankings-block__banner--matches\").text)\n",
    "    Points.append(table_soup.find('td', class_=\"rankings-block__banner--points\").text)\n",
    "    Ratings.append(table_soup.find('td', class_=\"rankings-block__banner--rating u-text-right\").text.strip())\n",
    "except Exception as error:\n",
    "    print(\"Following exception occured while adding 1st players values to the list:\")\n",
    "    print(error)\n",
    "else:\n",
    "    err+=1\n",
    "\n",
    "try:\n",
    "    n=0\n",
    "    for i in range(1,10):\n",
    "        Names.append(table_soup_Name_Tags[i].text)\n",
    "        Matches.append(table_soup_Matches_Points_Tags[n].text)\n",
    "        Points.append(table_soup_Matches_Points_Tags[n+1].text)\n",
    "        n = n+2\n",
    "        Ratings.append(table_soup_Rating_Tags[i].text)\n",
    "except Exception as error:\n",
    "    print(\"Following error occured while adding the remaining 9 values to the list\")\n",
    "    print(error)\n",
    "else:\n",
    "    err+=1  \n",
    "\n",
    "if err == 2:\n",
    "    print(\"All data found!\")\n",
    "else:\n",
    "    print(\"Something went wrong!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a321d36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T17:32:59.867148Z",
     "start_time": "2023-05-28T17:32:59.854148Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team Name</th>\n",
       "      <th>Matches Played</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>23</td>\n",
       "      <td>2,714</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>20</td>\n",
       "      <td>2,316</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>33</td>\n",
       "      <td>3,807</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>27</td>\n",
       "      <td>2,806</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>England</td>\n",
       "      <td>24</td>\n",
       "      <td>2,426</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>19</td>\n",
       "      <td>1,910</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>25</td>\n",
       "      <td>2,451</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>10</td>\n",
       "      <td>878</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>21</td>\n",
       "      <td>1,682</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>25</td>\n",
       "      <td>1,797</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Team Name Matches Played Points Rating\n",
       "0     Australia             23  2,714    118\n",
       "1      Pakistan             20  2,316    115\n",
       "2         India             33  3,807    104\n",
       "3   New Zealand             27  2,806    101\n",
       "4       England             24  2,426    101\n",
       "5  South Africa             19  1,910     98\n",
       "6    Bangladesh             25  2,451     88\n",
       "7   Afghanistan             10    878     80\n",
       "8     Sri Lanka             21  1,682     72\n",
       "9   West Indies             25  1,797     51"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Columns Names\n",
    "col = ['Team Name', 'Matches Played', 'Points', 'Rating']\n",
    "\n",
    "#Data\n",
    "data = list(zip(Names, Matches, Points, Ratings))\n",
    "\n",
    "#Creating the Dataframe\n",
    "df = pd.DataFrame(data= data, columns = col)\n",
    "\n",
    "#Displaying the Dataframe\n",
    "(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3fee70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T13:34:39.088716Z",
     "start_time": "2023-05-28T13:34:39.074747Z"
    }
   },
   "source": [
    "<h3>Top 10 ODI Batsmen along with the records of their team and rating.</h3>\n",
    "<br>Link: <a href = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\">Top 10 ODI Batsmen</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7372bd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T17:32:59.977179Z",
     "start_time": "2023-05-28T17:32:59.870149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The website allows Data Scraping.\n"
     ]
    }
   ],
   "source": [
    "URL = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\"\n",
    "r = requests.get(URL)\n",
    "print(is_allowed(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb0ba846",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T17:33:00.264156Z",
     "start_time": "2023-05-28T17:32:59.979150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data found!\n"
     ]
    }
   ],
   "source": [
    "#Fetching the soup\n",
    "content = r.text\n",
    "soup = Bs(content, 'html.parser')\n",
    "tb_soup = soup.find('table')\n",
    "\n",
    "#Lists to store the data\n",
    "Names = []\n",
    "Teams = []\n",
    "Ratings = []\n",
    "Career_Bests = []\n",
    "\n",
    "#Error Variable/s\n",
    "err = 0\n",
    "\n",
    "try:\n",
    "    \n",
    "    Names_Tb_tags = tb_soup.find_all('td', class_=\"table-body__cell rankings-table__name name\")\n",
    "    Teams_Tb_tags = tb_soup.find_all('span', class_=\"table-body__logo-text\")\n",
    "    Ratings_Tb_tags = tb_soup.find_all('td', class_=\"table-body__cell rating\")\n",
    "    CB_Tb_tags = tb_soup.find_all('td', class_=\"table-body__cell u-text-right u-hide-phablet\")\n",
    "    \n",
    "except Exception as error:\n",
    "    \n",
    "    print(\"Following error occured while fetching data from tags:\")\n",
    "    print(error)\n",
    "\n",
    "    \n",
    "try:\n",
    "    \n",
    "    Names.append(tb_soup.find('div', class_=\"rankings-block__banner--name-large\").text)\n",
    "    Teams.append(tb_soup.find('div', class_=\"rankings-block__banner--nationality\").text.strip())\n",
    "    Ratings.append(tb_soup.find('div', class_=\"u-text-left\").text.strip())\n",
    "    Career_Bests.append((tb_soup.find('div', class_=\"rankings-block__career-best\").text.strip()))\n",
    "    \n",
    "except Exception as error:\n",
    "    \n",
    "    print(\"Following error occured while storing data of the first player:\")\n",
    "    print(error)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    err+=1\n",
    "\n",
    "    \n",
    "try:\n",
    "    for i in range(0,9):\n",
    "        Names.append(Names_Tb_tags[i].text.strip())\n",
    "        Teams.append(Teams_Tb_tags[i].text)\n",
    "        Ratings.append(Ratings_Tb_tags[i].text)\n",
    "        Career_Bests.append(CB_Tb_tags[i].text.strip())\n",
    "        \n",
    "except Exception as error:\n",
    "    print(\"Following error occured while trying to get the data for remaining 9 players:\")\n",
    "    print(error)\n",
    "    \n",
    "else:\n",
    "    err+=1\n",
    "\n",
    "    \n",
    "if err == 2:\n",
    "    print(\"All data found!\")\n",
    "else:\n",
    "    print(\"Something went wrong!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73f29df7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T17:33:00.296150Z",
     "start_time": "2023-05-28T17:33:00.267149Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Career Best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>898 v West Indies, 10/06/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>777</td>\n",
       "      <td>796 v England, 19/07/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fakhar Zaman</td>\n",
       "      <td>PAK</td>\n",
       "      <td>755</td>\n",
       "      <td>784 v New Zealand, 29/04/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>745</td>\n",
       "      <td>815 v West Indies, 12/06/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shubman Gill</td>\n",
       "      <td>IND</td>\n",
       "      <td>738</td>\n",
       "      <td>738 v Australia, 22/03/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>726</td>\n",
       "      <td>880 v Pakistan, 26/01/2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Harry Tector</td>\n",
       "      <td>IRE</td>\n",
       "      <td>722</td>\n",
       "      <td>722 v Bangladesh, 14/05/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>719</td>\n",
       "      <td>911 v England, 12/07/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>718</td>\n",
       "      <td>813 v Sri Lanka, 10/03/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>707</td>\n",
       "      <td>885 v Sri Lanka, 06/07/2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player Name Team      Rating                    Career Best\n",
       "0             Babar Azam  PAK  Babar Azam  898 v West Indies, 10/06/2022\n",
       "1  Rassie van der Dussen   SA         777      796 v England, 19/07/2022\n",
       "2           Fakhar Zaman  PAK         755  784 v New Zealand, 29/04/2023\n",
       "3            Imam-ul-Haq  PAK         745  815 v West Indies, 12/06/2022\n",
       "4           Shubman Gill  IND         738    738 v Australia, 22/03/2023\n",
       "5           David Warner  AUS         726     880 v Pakistan, 26/01/2017\n",
       "6           Harry Tector  IRE         722   722 v Bangladesh, 14/05/2023\n",
       "7            Virat Kohli  IND         719      911 v England, 12/07/2018\n",
       "8        Quinton de Kock   SA         718    813 v Sri Lanka, 10/03/2019\n",
       "9           Rohit Sharma  IND         707    885 v Sri Lanka, 06/07/2019"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Columns Names\n",
    "col = ['Player Name', 'Team', 'Rating', 'Career Best']\n",
    "\n",
    "#Data\n",
    "data = list(zip(Names, Teams, Ratings, Career_Bests))\n",
    "\n",
    "#Creating the Dataframe\n",
    "df = pd.DataFrame(data= data, columns = col)\n",
    "\n",
    "#Displaying the Dataframe\n",
    "(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471e3eac",
   "metadata": {},
   "source": [
    "<h3>Top 10 ODI bowlers along with the records of their team and rating</h3>\n",
    "<br>Link: <a href = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\"> Top 10 ODI Bowlers </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2fd63f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T17:33:00.422150Z",
     "start_time": "2023-05-28T17:33:00.300151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The website allows Data Scraping.\n"
     ]
    }
   ],
   "source": [
    "URL = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\"\n",
    "r = requests.get(URL)\n",
    "print(is_allowed(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4154666b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T17:33:00.691156Z",
     "start_time": "2023-05-28T17:33:00.424151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data found!\n"
     ]
    }
   ],
   "source": [
    "#Fetching the soup\n",
    "content = r.text\n",
    "soup = Bs(content, 'html.parser')\n",
    "tb_soup = soup.find('table')\n",
    "\n",
    "#Lists to store the data\n",
    "Names = []\n",
    "Teams = []\n",
    "Ratings = []\n",
    "Career_Bests = []\n",
    "\n",
    "#Error Variable/s\n",
    "err=0\n",
    "\n",
    "try:\n",
    "    Names_Tb_tags = tb_soup.find_all('td', class_=\"table-body__cell rankings-table__name name\")\n",
    "    Teams_Tb_tags = tb_soup.find_all('span', class_=\"table-body__logo-text\")\n",
    "    Ratings_Tb_tags = tb_soup.find_all('td', class_=\"table-body__cell rating\")\n",
    "    CB_Tb_tags = tb_soup.find_all('td', class_=\"table-body__cell u-text-right u-hide-phablet\")\n",
    "    \n",
    "except Exception as error:\n",
    "    print(\"Following error occured while fetching data from tags:\")\n",
    "    print(error)\n",
    "    \n",
    "try:    \n",
    "    Names.append(tb_soup.find('div', class_=\"rankings-block__banner--name-large\").text)\n",
    "    Teams.append(tb_soup.find('div', class_=\"rankings-block__banner--nationality\").text.strip())\n",
    "    Ratings.append(tb_soup.find('div', class_=\"rankings-block__banner--rating\").text.strip())\n",
    "    Career_Bests.append((tb_soup.find('div', class_=\"rankings-block__career-best\").text.strip()))\n",
    "except Exception as error:\n",
    "    print(\"Following error occured while storing data of the first player:\")\n",
    "    print(error)\n",
    "else:\n",
    "    err+=1\n",
    "\n",
    "try:\n",
    "    for i in range(0,9):\n",
    "        Names.append(Names_Tb_tags[i].text.strip())\n",
    "        Teams.append(Teams_Tb_tags[i].text)\n",
    "        Ratings.append(Ratings_Tb_tags[i].text)\n",
    "        Career_Bests.append(CB_Tb_tags[i].text.strip())\n",
    "except Exception as error:\n",
    "    print(\"Following error occured while trying to get the data for remaining 9 players:\")\n",
    "    print(error)\n",
    "else:\n",
    "    err+=1\n",
    "\n",
    "if err == 2:\n",
    "    print(\"All data found!\")\n",
    "else:\n",
    "    print(\"Something went wrong!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b332acd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T17:33:00.723148Z",
     "start_time": "2023-05-28T17:33:00.693148Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Career Best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>705</td>\n",
       "      <td>733 v England, 26/01/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mohammed Siraj</td>\n",
       "      <td>IND</td>\n",
       "      <td>691</td>\n",
       "      <td>736 v New Zealand, 21/01/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mitchell Starc</td>\n",
       "      <td>AUS</td>\n",
       "      <td>686</td>\n",
       "      <td>783 v New Zealand, 29/03/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>667</td>\n",
       "      <td>691 v Bangladesh, 26/03/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>660</td>\n",
       "      <td>775 v Australia, 11/09/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>659</td>\n",
       "      <td>806 v Pakistan, 21/09/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Adam Zampa</td>\n",
       "      <td>AUS</td>\n",
       "      <td>652</td>\n",
       "      <td>655 v England, 22/11/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>637</td>\n",
       "      <td>712 v Ireland, 24/01/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mohammad Nabi</td>\n",
       "      <td>AFG</td>\n",
       "      <td>631</td>\n",
       "      <td>657 v Zimbabwe, 09/06/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>PAK</td>\n",
       "      <td>630</td>\n",
       "      <td>688 v West Indies, 10/06/2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Player Name Team Rating                    Career Best\n",
       "0    Josh Hazlewood  AUS    705      733 v England, 26/01/2018\n",
       "1    Mohammed Siraj  IND    691  736 v New Zealand, 21/01/2023\n",
       "2    Mitchell Starc  AUS    686  783 v New Zealand, 29/03/2015\n",
       "3        Matt Henry   NZ    667   691 v Bangladesh, 26/03/2021\n",
       "4       Trent Boult   NZ    660    775 v Australia, 11/09/2022\n",
       "5       Rashid Khan  AFG    659     806 v Pakistan, 21/09/2018\n",
       "6        Adam Zampa  AUS    652      655 v England, 22/11/2022\n",
       "7  Mujeeb Ur Rahman  AFG    637      712 v Ireland, 24/01/2021\n",
       "8     Mohammad Nabi  AFG    631     657 v Zimbabwe, 09/06/2022\n",
       "9    Shaheen Afridi  PAK    630  688 v West Indies, 10/06/2022"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Columns Names\n",
    "col = ['Player Name', 'Team', 'Rating', 'Career Best']\n",
    "\n",
    "#Data\n",
    "data = list(zip(Names, Teams, Ratings, Career_Bests))\n",
    "\n",
    "#Creating the Dataframe\n",
    "df = pd.DataFrame(data= data, columns = col)\n",
    "\n",
    "#Displaying the Dataframe\n",
    "(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd067dd",
   "metadata": {},
   "source": [
    "<H2> Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame:</H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410aac9f",
   "metadata": {},
   "source": [
    "<h3>Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.</h3>\n",
    "<br>Link: <A href = \"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\"> Women's ODI Team Rankings </A>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fed3f9db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T17:33:00.849163Z",
     "start_time": "2023-05-28T17:33:00.726150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The website allows Data Scraping.\n"
     ]
    }
   ],
   "source": [
    "URL = \"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\"\n",
    "r = requests.get(URL)\n",
    "print(is_allowed(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf724acf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T17:33:01.008150Z",
     "start_time": "2023-05-28T17:33:00.851153Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data found!\n"
     ]
    }
   ],
   "source": [
    "#Fetching the soup\n",
    "content = r.text\n",
    "soup = Bs(content, 'html.parser')\n",
    "table_soup = soup.find('table')\n",
    "\n",
    "#Lists to store the data\n",
    "Names = []\n",
    "Matches = []\n",
    "Points = []\n",
    "Ratings = []\n",
    "\n",
    "#Error Variable/s\n",
    "err=0\n",
    "\n",
    "try:\n",
    "    \n",
    "    table_soup_Name_Tags = table_soup.find_all('span', class_=\"u-hide-phablet\")\n",
    "    table_soup_Matches_Points_Tags = table_soup.find_all('td', class_=\"table-body__cell u-center-text\")\n",
    "    table_soup_Rating_Tags = table_soup.find_all('td', class_=\"table-body__cell u-text-right rating\")\n",
    "    \n",
    "except Exception as error:\n",
    "    print(\"Following error occured while fetching data from tags:\")\n",
    "    print(error)\n",
    "\n",
    "try:\n",
    "    Names.append(table_soup.find('span', class_=\"u-hide-phablet\").text)\n",
    "    Matches.append(table_soup.find('td', class_=\"rankings-block__banner--matches\").text)\n",
    "    Points.append(table_soup.find('td', class_=\"rankings-block__banner--points\").text)\n",
    "    Ratings.append(table_soup.find('td', class_=\"rankings-block__banner--rating u-text-right\").text.strip())\n",
    "except Exception as error:\n",
    "    print(\"Following error occured while storing data of the first player:\")\n",
    "    print(error)\n",
    "else:\n",
    "        err+=1\n",
    "\n",
    "try:        \n",
    "    n=0\n",
    "    for i in range(1,10):\n",
    "        Names.append(table_soup_Name_Tags[i].text)\n",
    "        Matches.append(table_soup_Matches_Points_Tags[n].text)\n",
    "        Points.append(table_soup_Matches_Points_Tags[n+1].text)\n",
    "        n = n+2\n",
    "        Ratings.append(table_soup_Rating_Tags[i].text)\n",
    "except Exception as error:\n",
    "    print(\"Following error occured while trying to get the data for remaining 9 players:\")\n",
    "    print(error)\n",
    "else:\n",
    "    err+=1\n",
    "\n",
    "if err == 2:\n",
    "    print(\"All data found!\")\n",
    "else:\n",
    "    print(\"Something went wrong!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "989e3c10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T17:33:01.040149Z",
     "start_time": "2023-05-28T17:33:01.012150Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team Name</th>\n",
       "      <th>Matches Played</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>21</td>\n",
       "      <td>3,603</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>28</td>\n",
       "      <td>3,342</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>26</td>\n",
       "      <td>3,098</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>27</td>\n",
       "      <td>2,820</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>25</td>\n",
       "      <td>2,553</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>27</td>\n",
       "      <td>2,535</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>11</td>\n",
       "      <td>821</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>14</td>\n",
       "      <td>977</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>27</td>\n",
       "      <td>1,678</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>9</td>\n",
       "      <td>479</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Team Name Matches Played Points Rating\n",
       "0     Australia             21  3,603    172\n",
       "1       England             28  3,342    119\n",
       "2  South Africa             26  3,098    104\n",
       "3         India             27  2,820    102\n",
       "4   New Zealand             25  2,553     94\n",
       "5   West Indies             27  2,535     75\n",
       "6      Thailand             11    821     70\n",
       "7    Bangladesh             14    977     62\n",
       "8      Pakistan             27  1,678     53\n",
       "9     Sri Lanka              9    479     39"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Columns Names\n",
    "col = ['Team Name', 'Matches Played', 'Points', 'Rating']\n",
    "\n",
    "#Data\n",
    "data = list(zip(Names, Matches, Points, Ratings))\n",
    "\n",
    "#Creating the Dataframe\n",
    "df = pd.DataFrame(data= data, columns = col)\n",
    "\n",
    "#Displaying the Dataframe\n",
    "(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda54604",
   "metadata": {},
   "source": [
    "<H3>Top 10 women’s ODI Batting players along with the records of their team and rating.</H3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197ae476",
   "metadata": {},
   "source": [
    "Link: <a href= \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\"> Top 10 ODI Batsmen - Women </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f652324",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T17:33:01.262148Z",
     "start_time": "2023-05-28T17:33:01.042148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The website allows Data Scraping.\n"
     ]
    }
   ],
   "source": [
    "URL = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\"\n",
    "r = requests.get(URL)\n",
    "print(is_allowed(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11c02a10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T17:33:01.640156Z",
     "start_time": "2023-05-28T17:33:01.269149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data found!\n"
     ]
    }
   ],
   "source": [
    "#Fetching the soup\n",
    "content = r.text\n",
    "soup = Bs(content, 'html.parser')\n",
    "tb_soup = soup.find('table')\n",
    "\n",
    "#Lists to store the data\n",
    "Names = []\n",
    "Teams = []\n",
    "Ratings = []\n",
    "Career_Bests = []\n",
    "\n",
    "#Error Variable/s\n",
    "err=0\n",
    "\n",
    "try:\n",
    "    Names_Tb_tags = tb_soup.find_all('td', class_=\"table-body__cell rankings-table__name name\")\n",
    "    Teams_Tb_tags = tb_soup.find_all('span', class_=\"table-body__logo-text\")\n",
    "    Ratings_Tb_tags = tb_soup.find_all('td', class_=\"table-body__cell rating\")\n",
    "    CB_Tb_tags = tb_soup.find_all('td', class_=\"table-body__cell u-text-right u-hide-phablet\")\n",
    "    \n",
    "except Exception as error:\n",
    "    print(\"Following error occured while fetching data from tags:\")\n",
    "    print(error)\n",
    "\n",
    "    \n",
    "try:\n",
    "    Names.append(tb_soup.find('div', class_=\"rankings-block__banner--name-large\").text)\n",
    "    Teams.append(tb_soup.find('div', class_=\"rankings-block__banner--nationality\").text.strip())\n",
    "    Ratings.append(tb_soup.find('div', class_=\"rankings-block__banner--rating\").text.strip())\n",
    "    Career_Bests.append((tb_soup.find('div', class_=\"rankings-block__career-best\").text.strip()))\n",
    "except Exception as error:\n",
    "    print(\"Following error occured while storing data of the first player:\")\n",
    "    print(error)\n",
    "else:\n",
    "    err+=1\n",
    "    \n",
    "\n",
    "try:\n",
    "    for i in range(0,9):\n",
    "        Names.append(Names_Tb_tags[i].text.strip())\n",
    "        Teams.append(Teams_Tb_tags[i].text)\n",
    "        Ratings.append(Ratings_Tb_tags[i].text)\n",
    "        Career_Bests.append(CB_Tb_tags[i].text.strip())\n",
    "except Exception as error:\n",
    "    print(\"Following error occured while trying to get the data for remaining 9 players:\")\n",
    "    print(error)\n",
    "else:\n",
    "    err+=1\n",
    "\n",
    "if err == 2:\n",
    "    print(\"All data found!\")\n",
    "else:\n",
    "    print(\"Something went wrong!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e7d2166",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T17:33:01.672150Z",
     "start_time": "2023-05-28T17:33:01.643148Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Career Best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>754</td>\n",
       "      <td>754 v Pakistan, 21/01/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>732</td>\n",
       "      <td>741 v Australia, 22/03/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>731</td>\n",
       "      <td>755 v South Africa, 15/07/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>717</td>\n",
       "      <td>834 v New Zealand, 24/02/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harmanpreet Kaur</td>\n",
       "      <td>IND</td>\n",
       "      <td>716</td>\n",
       "      <td>731 v England, 21/09/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>714</td>\n",
       "      <td>797 v England, 28/02/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chamari Athapaththu</td>\n",
       "      <td>SL</td>\n",
       "      <td>673</td>\n",
       "      <td>691 v South Africa, 14/02/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>626</td>\n",
       "      <td>766 v West Indies, 11/09/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>ENG</td>\n",
       "      <td>595</td>\n",
       "      <td>791 v India, 27/06/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>588</td>\n",
       "      <td>766 v Pakistan, 07/07/2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Player Name Team Rating                     Career Best\n",
       "0          Beth Mooney  AUS    754      754 v Pakistan, 21/01/2023\n",
       "1      Laura Wolvaardt   SA    732     741 v Australia, 22/03/2022\n",
       "2       Natalie Sciver  ENG    731  755 v South Africa, 15/07/2022\n",
       "3          Meg Lanning  AUS    717   834 v New Zealand, 24/02/2016\n",
       "4     Harmanpreet Kaur  IND    716       731 v England, 21/09/2022\n",
       "5      Smriti Mandhana  IND    714       797 v England, 28/02/2019\n",
       "6  Chamari Athapaththu   SL    673  691 v South Africa, 14/02/2019\n",
       "7         Ellyse Perry  AUS    626   766 v West Indies, 11/09/2019\n",
       "8       Tammy Beaumont  ENG    595         791 v India, 27/06/2021\n",
       "9      Stafanie Taylor   WI    588      766 v Pakistan, 07/07/2021"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Columns Names\n",
    "col = ['Player Name', 'Team', 'Rating', 'Career Best']\n",
    "\n",
    "#Data\n",
    "data = list(zip(Names, Teams, Ratings, Career_Bests))\n",
    "\n",
    "#Creating the Dataframe\n",
    "df = pd.DataFrame(data= data, columns = col)\n",
    "\n",
    "#Displaying the Dataframe\n",
    "(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d90ff3",
   "metadata": {},
   "source": [
    "<H3> Top 10 women’s ODI all-rounder along with the records of their team and rating. </H3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ff5248",
   "metadata": {},
   "source": [
    "Link: <a href = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\"> Top 10 ODI All-Rounders - Women </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a469a4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T17:33:01.783152Z",
     "start_time": "2023-05-28T17:33:01.676149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The website allows Data Scraping.\n"
     ]
    }
   ],
   "source": [
    "URL = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\"\n",
    "r = requests.get(URL)\n",
    "print(is_allowed(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e14fe191",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T17:33:01.958148Z",
     "start_time": "2023-05-28T17:33:01.785156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data found!\n"
     ]
    }
   ],
   "source": [
    "#Fetching the soup\n",
    "content = r.text\n",
    "soup = Bs(content, 'html.parser')\n",
    "tb_soup = soup.find('table')\n",
    "\n",
    "#Lists to store the data\n",
    "Names = []\n",
    "Teams = []\n",
    "Ratings = []\n",
    "Career_Bests = []\n",
    "\n",
    "#Error Variable/s\n",
    "err = 0\n",
    "\n",
    "try:\n",
    "    Names_Tb_tags = tb_soup.find_all('td', class_=\"table-body__cell rankings-table__name name\")\n",
    "    Teams_Tb_tags = tb_soup.find_all('span', class_=\"table-body__logo-text\")\n",
    "    Ratings_Tb_tags = tb_soup.find_all('td', class_=\"table-body__cell rating\")\n",
    "    CB_Tb_tags = tb_soup.find_all('td', class_=\"table-body__cell u-text-right u-hide-phablet\")\n",
    "\n",
    "    \n",
    "except Exception as error:\n",
    "    print(\"Following error occured while fetching data from tags:\")\n",
    "    print(error)\n",
    "    \n",
    "try:\n",
    "    Names.append(tb_soup.find('div', class_=\"rankings-block__banner--name-large\").text)\n",
    "    Teams.append(tb_soup.find('div', class_=\"rankings-block__banner--nationality\").text.strip())\n",
    "    Ratings.append(tb_soup.find('div', class_=\"rankings-block__banner--rating\").text.strip())\n",
    "    Career_Bests.append((tb_soup.find('div', class_=\"rankings-block__career-best\").text.strip()))\n",
    "except Exception as error:\n",
    "    print(\"Following error occured while storing data of the first player:\")\n",
    "    print(error)\n",
    "else:\n",
    "    err+=1\n",
    "    \n",
    "try:\n",
    "    for i in range(0,9):\n",
    "        Names.append(Names_Tb_tags[i].text.strip())\n",
    "        Teams.append(Teams_Tb_tags[i].text)\n",
    "        Ratings.append(Ratings_Tb_tags[i].text)\n",
    "        Career_Bests.append(CB_Tb_tags[i].text.strip())\n",
    "\n",
    "except Exception as error:\n",
    "    print(\"Following error occured while trying to get the data for remaining 9 players:\")\n",
    "    print(error)\n",
    "else:\n",
    "    err+=1\n",
    "\n",
    "if err == 2:\n",
    "    print(\"All data found!\")\n",
    "else:\n",
    "    print(\"Something went wrong!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab90acb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T17:33:01.989150Z",
     "start_time": "2023-05-28T17:33:01.960147Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Career Best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>WI</td>\n",
       "      <td>373</td>\n",
       "      <td>383 v England, 04/12/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>371</td>\n",
       "      <td>395 v South Africa, 11/07/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>366</td>\n",
       "      <td>548 v West Indies, 11/09/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>349</td>\n",
       "      <td>419 v West Indies, 10/09/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>NZ</td>\n",
       "      <td>336</td>\n",
       "      <td>356 v West Indies, 25/09/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>322</td>\n",
       "      <td>397 v South Africa, 09/10/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>292</td>\n",
       "      <td>292 v Pakistan, 21/01/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>250</td>\n",
       "      <td>308 v West Indies, 11/09/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nida Dar</td>\n",
       "      <td>PAK</td>\n",
       "      <td>232</td>\n",
       "      <td>232 v Australia, 21/01/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sophie Ecclestone</td>\n",
       "      <td>ENG</td>\n",
       "      <td>205</td>\n",
       "      <td>217 v South Africa, 31/03/2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Player Name Team Rating                     Career Best\n",
       "0    Hayley Matthews   WI    373       383 v England, 04/12/2022\n",
       "1     Natalie Sciver  ENG    371  395 v South Africa, 11/07/2022\n",
       "2       Ellyse Perry  AUS    366   548 v West Indies, 11/09/2019\n",
       "3     Marizanne Kapp   SA    349   419 v West Indies, 10/09/2021\n",
       "4        Amelia Kerr   NZ    336   356 v West Indies, 25/09/2022\n",
       "5      Deepti Sharma  IND    322  397 v South Africa, 09/10/2019\n",
       "6   Ashleigh Gardner  AUS    292      292 v Pakistan, 21/01/2023\n",
       "7      Jess Jonassen  AUS    250   308 v West Indies, 11/09/2019\n",
       "8           Nida Dar  PAK    232     232 v Australia, 21/01/2023\n",
       "9  Sophie Ecclestone  ENG    205  217 v South Africa, 31/03/2022"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Columns Names\n",
    "col = ['Player Name', 'Team', 'Rating', 'Career Best']\n",
    "\n",
    "#Data\n",
    "data = list(zip(Names, Teams, Ratings, Career_Bests))\n",
    "\n",
    "#Creating the Dataframe\n",
    "df = pd.DataFrame(data= data, columns = col)\n",
    "\n",
    "#Displaying the Dataframe\n",
    "(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b94c04b",
   "metadata": {},
   "source": [
    "<h2>Write a python program to scrape mentioned news details from the following link and\n",
    "make data frame -</h2>\n",
    "\n",
    "Link: <a href=\"https://www.cnbc.com/world/?region=world\"> CNBC World News </a>    \n",
    "\n",
    "<br><b>Include</b> -\n",
    "1. Headline\n",
    "2. Time\n",
    "3. News Link\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12b207d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T17:33:02.745462Z",
     "start_time": "2023-05-28T17:33:01.994151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The website allows Data Scraping.\n"
     ]
    }
   ],
   "source": [
    "URL = \"https://www.cnbc.com/world/?region=world\"\n",
    "r = requests.get(URL)\n",
    "print(is_allowed(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1725c53f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T17:33:02.921455Z",
     "start_time": "2023-05-28T17:33:02.747455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Data Found!\n"
     ]
    }
   ],
   "source": [
    "#Fetching the soup\n",
    "content = r.text\n",
    "soup = Bs(content, 'html.parser')\n",
    "\n",
    "#Lists to store the data\n",
    "Timestamps = []\n",
    "Headlines = []\n",
    "Links = []\n",
    "\n",
    "#Error Variable/s\n",
    "err = 0\n",
    "\n",
    "try:\n",
    "    Timestamp_tags = soup.find_all('time', class_ = 'LatestNews-timestamp')\n",
    "    Headline_Link_tags = soup.find_all('a', class_ = 'LatestNews-headline')\n",
    "except Exception as error:\n",
    "    print(\"Following error occured while fetching data from tags:\")\n",
    "    print(error)\n",
    "    \n",
    "    \n",
    "#if len(Timestamp_tags) == len(Headline_Link_tags):\n",
    "#    print(\"Same Length\") > TRUE\n",
    "\n",
    "try:\n",
    "    for i in range(0, len(Timestamp_tags)):\n",
    "        Timestamps.append(Timestamp_tags[i].text)\n",
    "        Headlines.append(Headline_Link_tags[i].text)\n",
    "        Links.append(Headline_Link_tags[i]['href'])\n",
    "except Exception as error:\n",
    "    print(\"Following error occured while adding data to lists:\")\n",
    "    print(error)\n",
    "else:\n",
    "    err+=1\n",
    "    \n",
    "if err == 1:\n",
    "    print(\"All Data Found!\")\n",
    "else:\n",
    "    print(\"Something went wrong!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02c78980",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T17:33:02.953496Z",
     "start_time": "2023-05-28T17:33:02.923498Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>When</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Debt ceiling deal will be 'transformational' f...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/28/debt-ceiling-d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NYC, Las Vegas, D.C.: Free wellness activities...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/28/nyc-las-vegas-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Content creators bring in up to $150/hour film...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/28/content-creato...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34-year-old makes up to $167 an hour nannying ...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/28/gloria-richard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This winning fund puts a spin on emerging mark...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/28/this-winning-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASCO will put the focus on the cancer fight. T...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/28/asco-will-focu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Now Boarding: Why airlines are turning to bigg...</td>\n",
       "      <td>6 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/28/now-boarding-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Global demand for streaming Asian movies, TV g...</td>\n",
       "      <td>6 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/28/squid-game-eea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>These are the cheapest tech stocks in the S&amp;P 500</td>\n",
       "      <td>6 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/28/these-are-the-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Turkey votes in runoff election after candidat...</td>\n",
       "      <td>14 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/28/turkey-electio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>White House and Republicans reach a tentative ...</td>\n",
       "      <td>17 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/27/white-house-an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>State Farm to stop accepting homeowners insura...</td>\n",
       "      <td>23 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/27/state-farm-to-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>How Janie Deegan built Janie's Life-Changing B...</td>\n",
       "      <td>May 27, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/27/how-janie-deeg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Top 10 cheapest places in the U.S. to buy a be...</td>\n",
       "      <td>May 27, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/27/cheapest-place...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mark Cuban calls Elon Musk’s Twitter algorithm...</td>\n",
       "      <td>May 27, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/27/mark-cuban-say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3 investing tips as the federal debt ceiling '...</td>\n",
       "      <td>May 27, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/27/how-to-invest-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Microsoft keyboard users are ‘devastated’ afte...</td>\n",
       "      <td>May 27, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/27/microsoft-keyb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Steve Adcock: The 3 'stupidest' myths I've hea...</td>\n",
       "      <td>May 27, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/27/steve-adcock-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Chip stocks AMD and Nvidia are among the most ...</td>\n",
       "      <td>May 27, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/27/chip-stocks-am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Analysts are pounding the table for these must...</td>\n",
       "      <td>May 27, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/27/analysts-are-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Lower-income consumers pay for wealthy's credi...</td>\n",
       "      <td>May 27, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/27/lower-income-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>How Mastercard has outperformed Visa</td>\n",
       "      <td>May 27, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/27/how-mastercard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Why commercial real estate firms are joining t...</td>\n",
       "      <td>May 27, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/27/commercial-rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Japan stocks are on fire this year. Why the ra...</td>\n",
       "      <td>May 27, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/27/japan-stocks-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Marvell Technology shares surge after earnings...</td>\n",
       "      <td>May 26, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/26/marvell-techno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>The tech trade is back, driven by A.I. craze a...</td>\n",
       "      <td>May 26, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/26/tech-stocks-ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Next week hints at only short-lived debt deal ...</td>\n",
       "      <td>May 26, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/26/next-week-hint...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Treasury says it could run out of money June 5...</td>\n",
       "      <td>May 26, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/26/treasury-says-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Disney rips DeSantis bid to disqualify judge i...</td>\n",
       "      <td>May 26, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/26/disney-rips-de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Why the pause on student loan payments has bee...</td>\n",
       "      <td>May 26, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/26/the-pause-on-s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headline          When  \\\n",
       "0   Debt ceiling deal will be 'transformational' f...   2 Hours Ago   \n",
       "1   NYC, Las Vegas, D.C.: Free wellness activities...   4 Hours Ago   \n",
       "2   Content creators bring in up to $150/hour film...   4 Hours Ago   \n",
       "3   34-year-old makes up to $167 an hour nannying ...   5 Hours Ago   \n",
       "4   This winning fund puts a spin on emerging mark...   5 Hours Ago   \n",
       "5   ASCO will put the focus on the cancer fight. T...   5 Hours Ago   \n",
       "6   Now Boarding: Why airlines are turning to bigg...   6 Hours Ago   \n",
       "7   Global demand for streaming Asian movies, TV g...   6 Hours Ago   \n",
       "8   These are the cheapest tech stocks in the S&P 500   6 Hours Ago   \n",
       "9   Turkey votes in runoff election after candidat...  14 Hours Ago   \n",
       "10  White House and Republicans reach a tentative ...  17 Hours Ago   \n",
       "11  State Farm to stop accepting homeowners insura...  23 Hours Ago   \n",
       "12  How Janie Deegan built Janie's Life-Changing B...  May 27, 2023   \n",
       "13  Top 10 cheapest places in the U.S. to buy a be...  May 27, 2023   \n",
       "14  Mark Cuban calls Elon Musk’s Twitter algorithm...  May 27, 2023   \n",
       "15  3 investing tips as the federal debt ceiling '...  May 27, 2023   \n",
       "16  Microsoft keyboard users are ‘devastated’ afte...  May 27, 2023   \n",
       "17  Steve Adcock: The 3 'stupidest' myths I've hea...  May 27, 2023   \n",
       "18  Chip stocks AMD and Nvidia are among the most ...  May 27, 2023   \n",
       "19  Analysts are pounding the table for these must...  May 27, 2023   \n",
       "20  Lower-income consumers pay for wealthy's credi...  May 27, 2023   \n",
       "21               How Mastercard has outperformed Visa  May 27, 2023   \n",
       "22  Why commercial real estate firms are joining t...  May 27, 2023   \n",
       "23  Japan stocks are on fire this year. Why the ra...  May 27, 2023   \n",
       "24  Marvell Technology shares surge after earnings...  May 26, 2023   \n",
       "25  The tech trade is back, driven by A.I. craze a...  May 26, 2023   \n",
       "26  Next week hints at only short-lived debt deal ...  May 26, 2023   \n",
       "27  Treasury says it could run out of money June 5...  May 26, 2023   \n",
       "28  Disney rips DeSantis bid to disqualify judge i...  May 26, 2023   \n",
       "29  Why the pause on student loan payments has bee...  May 26, 2023   \n",
       "\n",
       "                                                 Link  \n",
       "0   https://www.cnbc.com/2023/05/28/debt-ceiling-d...  \n",
       "1   https://www.cnbc.com/2023/05/28/nyc-las-vegas-...  \n",
       "2   https://www.cnbc.com/2023/05/28/content-creato...  \n",
       "3   https://www.cnbc.com/2023/05/28/gloria-richard...  \n",
       "4   https://www.cnbc.com/2023/05/28/this-winning-f...  \n",
       "5   https://www.cnbc.com/2023/05/28/asco-will-focu...  \n",
       "6   https://www.cnbc.com/2023/05/28/now-boarding-a...  \n",
       "7   https://www.cnbc.com/2023/05/28/squid-game-eea...  \n",
       "8   https://www.cnbc.com/2023/05/28/these-are-the-...  \n",
       "9   https://www.cnbc.com/2023/05/28/turkey-electio...  \n",
       "10  https://www.cnbc.com/2023/05/27/white-house-an...  \n",
       "11  https://www.cnbc.com/2023/05/27/state-farm-to-...  \n",
       "12  https://www.cnbc.com/2023/05/27/how-janie-deeg...  \n",
       "13  https://www.cnbc.com/2023/05/27/cheapest-place...  \n",
       "14  https://www.cnbc.com/2023/05/27/mark-cuban-say...  \n",
       "15  https://www.cnbc.com/2023/05/27/how-to-invest-...  \n",
       "16  https://www.cnbc.com/2023/05/27/microsoft-keyb...  \n",
       "17  https://www.cnbc.com/2023/05/27/steve-adcock-t...  \n",
       "18  https://www.cnbc.com/2023/05/27/chip-stocks-am...  \n",
       "19  https://www.cnbc.com/2023/05/27/analysts-are-p...  \n",
       "20  https://www.cnbc.com/2023/05/27/lower-income-a...  \n",
       "21  https://www.cnbc.com/2023/05/27/how-mastercard...  \n",
       "22  https://www.cnbc.com/2023/05/27/commercial-rea...  \n",
       "23  https://www.cnbc.com/2023/05/27/japan-stocks-a...  \n",
       "24  https://www.cnbc.com/2023/05/26/marvell-techno...  \n",
       "25  https://www.cnbc.com/2023/05/26/tech-stocks-ar...  \n",
       "26  https://www.cnbc.com/2023/05/26/next-week-hint...  \n",
       "27  https://www.cnbc.com/2023/05/26/treasury-says-...  \n",
       "28  https://www.cnbc.com/2023/05/26/disney-rips-de...  \n",
       "29  https://www.cnbc.com/2023/05/26/the-pause-on-s...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Columns Names\n",
    "col = ['Headline', 'When', 'Link']\n",
    "\n",
    "#Data\n",
    "data = list(zip(Headlines, Timestamps, Links))\n",
    "\n",
    "#Creating the Dataframe\n",
    "df = pd.DataFrame(data= data, columns = col)\n",
    "\n",
    "#Displaying the Dataframe\n",
    "(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6121dd9",
   "metadata": {},
   "source": [
    "<h2> Write a python program to scrape the details of most downloaded articles from AI in last 90\n",
    "days.</h2>\n",
    "<br>\n",
    "Link: <A href = \"https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\"> Elsevier's Most downloaded AI articles </A>\n",
    "<br>\n",
    "<br>Scrape below mentioned details and make data frame:\n",
    "<br>i) Paper Title\n",
    "<br>ii) Authors\n",
    "<br>iii) Published Date\n",
    "<br>iv) Paper URL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2fbfec6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T17:33:03.444087Z",
     "start_time": "2023-05-28T17:33:02.955457Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The website allows Data Scraping.\n"
     ]
    }
   ],
   "source": [
    "URL = \"https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\"\n",
    "r = requests.get(URL)\n",
    "print(is_allowed(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10205bce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T17:33:03.505762Z",
     "start_time": "2023-05-28T17:33:03.446761Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Data Found!\n"
     ]
    }
   ],
   "source": [
    "#Fetching the soup\n",
    "content = r.text\n",
    "soup = Bs(content, 'html.parser')\n",
    "\n",
    "#Lists to store the data\n",
    "Title = []\n",
    "Authors = []\n",
    "Date = []\n",
    "Link = []\n",
    "\n",
    "#Error Variable/s\n",
    "err = 0\n",
    "\n",
    "#if len(soup.find_all('a', class_ = 'sc-5smygv-0 fIXTHm')) == len(soup.find_all('span', class_ = \"sc-1w3fpd7-0 dnCnAO\")) and len(soup.find_all('a', class_ = 'sc-5smygv-0 fIXTHm'))== len(soup.find_all('span', class_ = \"sc-1thf9ly-2 dvggWt\")):\n",
    "#   print(\"Same Length\") > True\n",
    "\n",
    "try:\n",
    "    Title_Link_Tags = soup.find_all('a', class_ = 'sc-5smygv-0 fIXTHm')\n",
    "    Authors_Tags = soup.find_all('span', class_ = \"sc-1w3fpd7-0 dnCnAO\")\n",
    "    Date_Tags = soup.find_all('span', class_ = \"sc-1thf9ly-2 dvggWt\")\n",
    "except Exception as error:\n",
    "    print(\"Following error occured while fetching data from tags:\")\n",
    "    print(error)\n",
    "    \n",
    "try:\n",
    "    for i in range(0, len(soup.find_all('a', class_ = 'sc-5smygv-0 fIXTHm'))):\n",
    "        Title.append(Title_Link_Tags[i].text)\n",
    "        Link.append(Title_Link_Tags[i]['href'])\n",
    "        Authors.append(Authors_Tags[i].text)\n",
    "        Date.append(Date_Tags[i].text)\n",
    "except Exception as error:\n",
    "    print(\"Following error occured while adding data to lists:\")\n",
    "    print(error)\n",
    "else:\n",
    "    err+=1\n",
    "    \n",
    "    \n",
    "if err == 1:\n",
    "    print(\"All Data Found!\")\n",
    "else:\n",
    "    print(\"Something went wrong!\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2319bac7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T17:33:03.537802Z",
     "start_time": "2023-05-28T17:33:03.507766Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Paper URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>David Silver, Satinder Singh, Doina Precup, Ri...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Tim Miller</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Margaret A. Boden</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Guni Sharon, Roni Stern, Ariel Felner, Nathan ...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Knowledge graphs as tools for explainable mach...</td>\n",
       "      <td>Ilaria Tiddi, Stefan Schlobach</td>\n",
       "      <td>January 2022</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Henry Prakken, Giovanni Sartor</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Richard S. Sutton, Doina Precup, Satinder Singh</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Kjersti Aas, Martin Jullum, Anders Løland</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Wenhan Luo, Junliang Xing and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Saurabh Arora, Prashant Doshi</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>Jasper van der Waa, Elisabeth Nieuwburg, Anita...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Explainable AI tools for legal reasoning about...</td>\n",
       "      <td>Joe Collenette, Katie Atkinson, Trevor Bench-C...</td>\n",
       "      <td>April 2023</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hard choices in artificial intelligence</td>\n",
       "      <td>Roel Dobbe, Thomas Krendl Gilbert, Yonatan Mintz</td>\n",
       "      <td>November 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Assessing the communication gap between AI mod...</td>\n",
       "      <td>Oskar Wysocki, Jessica Katharine Davies and 5 ...</td>\n",
       "      <td>March 2023</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Eoin M. Kenny, Courtney Ford, Molly Quinn, Mar...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Nolan Bard, Jakob N. Foerster and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Ron Kohavi, George H. John</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Séverin Lemaignan, Mathieu Warnier and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Tomáš Kliegr, Štěpán Bahník, Johannes Fürnkranz</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The multifaceted impact of Ada Lovelace in the...</td>\n",
       "      <td>Luigia Carlucci Aiello</td>\n",
       "      <td>June 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Robot ethics: Mapping the issues for a mechani...</td>\n",
       "      <td>Patrick Lin, Keith Abney, George Bekey</td>\n",
       "      <td>April 2011</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Reward (Mis)design for autonomous driving</td>\n",
       "      <td>W. Bradley Knox, Alessandro Allievi and 3 more</td>\n",
       "      <td>March 2023</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Planning and acting in partially observable st...</td>\n",
       "      <td>Leslie Pack Kaelbling, Michael L. Littman, Ant...</td>\n",
       "      <td>May 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What do we want from Explainable Artificial In...</td>\n",
       "      <td>Markus Langer, Daniel Oster and 6 more</td>\n",
       "      <td>July 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Paper Title  \\\n",
       "0                                    Reward is enough   \n",
       "1   Explanation in artificial intelligence: Insigh...   \n",
       "2              Creativity and artificial intelligence   \n",
       "3   Conflict-based search for optimal multi-agent ...   \n",
       "4   Knowledge graphs as tools for explainable mach...   \n",
       "5   Law and logic: A review from an argumentation ...   \n",
       "6   Between MDPs and semi-MDPs: A framework for te...   \n",
       "7   Explaining individual predictions when feature...   \n",
       "8       Multiple object tracking: A literature review   \n",
       "9   A survey of inverse reinforcement learning: Ch...   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   \n",
       "11  Explainable AI tools for legal reasoning about...   \n",
       "12            Hard choices in artificial intelligence   \n",
       "13  Assessing the communication gap between AI mod...   \n",
       "14  Explaining black-box classifiers using post-ho...   \n",
       "15  The Hanabi challenge: A new frontier for AI re...   \n",
       "16              Wrappers for feature subset selection   \n",
       "17  Artificial cognition for social human–robot in...   \n",
       "18  A review of possible effects of cognitive bias...   \n",
       "19  The multifaceted impact of Ada Lovelace in the...   \n",
       "20  Robot ethics: Mapping the issues for a mechani...   \n",
       "21          Reward (Mis)design for autonomous driving   \n",
       "22  Planning and acting in partially observable st...   \n",
       "23  What do we want from Explainable Artificial In...   \n",
       "\n",
       "                                              Authors  Published Date  \\\n",
       "0   David Silver, Satinder Singh, Doina Precup, Ri...    October 2021   \n",
       "1                                         Tim Miller    February 2019   \n",
       "2                                  Margaret A. Boden      August 1998   \n",
       "3   Guni Sharon, Roni Stern, Ariel Felner, Nathan ...   February 2015   \n",
       "4                     Ilaria Tiddi, Stefan Schlobach     January 2022   \n",
       "5                     Henry Prakken, Giovanni Sartor     October 2015   \n",
       "6    Richard S. Sutton, Doina Precup, Satinder Singh      August 1999   \n",
       "7          Kjersti Aas, Martin Jullum, Anders Løland   September 2021   \n",
       "8                Wenhan Luo, Junliang Xing and 4 more      April 2021   \n",
       "9                      Saurabh Arora, Prashant Doshi      August 2021   \n",
       "10  Jasper van der Waa, Elisabeth Nieuwburg, Anita...   February 2021   \n",
       "11  Joe Collenette, Katie Atkinson, Trevor Bench-C...      April 2023   \n",
       "12  Roel Dobbe, Thomas Krendl Gilbert, Yonatan Mintz    November 2021   \n",
       "13  Oskar Wysocki, Jessica Katharine Davies and 5 ...      March 2023   \n",
       "14  Eoin M. Kenny, Courtney Ford, Molly Quinn, Mar...        May 2021   \n",
       "15          Nolan Bard, Jakob N. Foerster and 13 more      March 2020   \n",
       "16                        Ron Kohavi, George H. John    December 1997   \n",
       "17      Séverin Lemaignan, Mathieu Warnier and 3 more       June 2017   \n",
       "18   Tomáš Kliegr, Štěpán Bahník, Johannes Fürnkranz        June 2021   \n",
       "19                            Luigia Carlucci Aiello        June 2016   \n",
       "20            Patrick Lin, Keith Abney, George Bekey       April 2011   \n",
       "21     W. Bradley Knox, Alessandro Allievi and 3 more      March 2023   \n",
       "22  Leslie Pack Kaelbling, Michael L. Littman, Ant...        May 1998   \n",
       "23             Markus Langer, Daniel Oster and 6 more       July 2021   \n",
       "\n",
       "                                            Paper URL  \n",
       "0   https://www.sciencedirect.com/science/article/...  \n",
       "1   https://www.sciencedirect.com/science/article/...  \n",
       "2   https://www.sciencedirect.com/science/article/...  \n",
       "3   https://www.sciencedirect.com/science/article/...  \n",
       "4   https://www.sciencedirect.com/science/article/...  \n",
       "5   https://www.sciencedirect.com/science/article/...  \n",
       "6   https://www.sciencedirect.com/science/article/...  \n",
       "7   https://www.sciencedirect.com/science/article/...  \n",
       "8   https://www.sciencedirect.com/science/article/...  \n",
       "9   https://www.sciencedirect.com/science/article/...  \n",
       "10  https://www.sciencedirect.com/science/article/...  \n",
       "11  https://www.sciencedirect.com/science/article/...  \n",
       "12  https://www.sciencedirect.com/science/article/...  \n",
       "13  https://www.sciencedirect.com/science/article/...  \n",
       "14  https://www.sciencedirect.com/science/article/...  \n",
       "15  https://www.sciencedirect.com/science/article/...  \n",
       "16  https://www.sciencedirect.com/science/article/...  \n",
       "17  https://www.sciencedirect.com/science/article/...  \n",
       "18  https://www.sciencedirect.com/science/article/...  \n",
       "19  https://www.sciencedirect.com/science/article/...  \n",
       "20  https://www.sciencedirect.com/science/article/...  \n",
       "21  https://www.sciencedirect.com/science/article/...  \n",
       "22  https://www.sciencedirect.com/science/article/...  \n",
       "23  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Columns Names\n",
    "col = ['Paper Title', 'Authors', 'Published Date', 'Paper URL']\n",
    "\n",
    "#Data\n",
    "data = list(zip(Title, Authors, Date, Link))\n",
    "\n",
    "#Creating the Dataframe\n",
    "df = pd.DataFrame(data= data, columns = col)\n",
    "\n",
    "#Displaying the Dataframe\n",
    "(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117fb07e",
   "metadata": {},
   "source": [
    "<h2>Write a python program to scrape mentioned details from the link below and make data frame: </h2>\n",
    "\n",
    "Link: <a href = \"dineout.co.in\"> Dineout </a>   \n",
    "<br><b>Include</b> -\n",
    "<br>i) Restaurant name\n",
    "<br>ii) Cuisine\n",
    "<br>iii) Location\n",
    "<br>iv) Ratings\n",
    "<br>v) Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "40d90e00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T17:33:04.104759Z",
     "start_time": "2023-05-28T17:33:03.539761Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The website allows Data Scraping.\n"
     ]
    }
   ],
   "source": [
    "URL = \"https://www.dineout.co.in/delhi-restaurants/welcome-back\"\n",
    "r = requests.get(URL)\n",
    "print(is_allowed(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7832f0d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T17:33:04.216394Z",
     "start_time": "2023-05-28T17:33:04.106761Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Data Found!\n"
     ]
    }
   ],
   "source": [
    "#Fetching the soup\n",
    "content = r.text\n",
    "soup = Bs(content, 'html.parser')\n",
    "\n",
    "#Lists to store the data\n",
    "Name = []\n",
    "Cuisines = []\n",
    "Location = []\n",
    "Ratings = []\n",
    "Img_Url = []\n",
    "\n",
    "#Error Variable/s\n",
    "err = 0\n",
    "\n",
    "\n",
    "try:\n",
    "    Name_Tags = soup.find_all('a', class_ = 'restnt-name ellipsis')\n",
    "    Location_Tags = soup.find_all('div', class_ = \"restnt-loc ellipsis\")\n",
    "    Rating_Tags = soup.find_all('div', class_ = 'restnt-rating rating-4')\n",
    "    Img_Tags = soup.find_all('img', class_ = 'no-img')\n",
    "    Cuisine_soup = soup.find_all('span', class_ = \"double-line-ellipsis\")\n",
    "except Exception as error:\n",
    "    print(\"Following error occured while fetching data from tags:\")\n",
    "    print(error)\n",
    "    \n",
    "try:\n",
    "    for i in range(0, len(Name_Tags)):\n",
    "        Name.append(Name_Tags[i].text)\n",
    "        Location.append(Location_Tags[i].text)\n",
    "        Ratings.append(Rating_Tags[i].text)\n",
    "        Img_Url.append(Img_Tags[i]['data-src'])\n",
    "        Cuisines.append([tag.text for tag in Cuisine_soup[i].find_all('a')])\n",
    "except Exception as error:\n",
    "    print(\"Following error occured while adding data to lists:\")\n",
    "    print(error)\n",
    "else:\n",
    "    err+=1\n",
    "    \n",
    "    \n",
    "if err == 1:\n",
    "    print(\"All Data Found!\")\n",
    "else:\n",
    "    print(\"Something went wrong!\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "335a7fe3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T17:33:04.248355Z",
     "start_time": "2023-05-28T17:33:04.218354Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant name</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Image URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Local</td>\n",
       "      <td>[North Indian, Asian, Continental]</td>\n",
       "      <td>Scindia House,Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tamasha</td>\n",
       "      <td>[Continental, Asian, Italian, North Indian]</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ministry Of Beer</td>\n",
       "      <td>[North Indian, Continental, American, Asian]</td>\n",
       "      <td>M-Block,Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Openhouse Cafe</td>\n",
       "      <td>[North Indian, Asian, Italian]</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unplugged Courtyard</td>\n",
       "      <td>[North Indian, Italian, Chinese, Turkish, Cont...</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Junkyard Cafe</td>\n",
       "      <td>[North Indian, Continental, Chinese, Fast Food]</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Station Bar</td>\n",
       "      <td>[Italian, Chinese, North Indian, Fast Food]</td>\n",
       "      <td>F-Block,Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Berco's</td>\n",
       "      <td>[Chinese, Thai]</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>QBA</td>\n",
       "      <td>[North Indian, Continental, Italian]</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chido</td>\n",
       "      <td>[North Indian, Italian, Continental, Asian, Fi...</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>38 Barracks</td>\n",
       "      <td>[North Indian, Chinese, Continental]</td>\n",
       "      <td>M-Block,Connaught Place, Central Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ardor 2.1 Restaurant and Lounge</td>\n",
       "      <td>[North Indian, Chinese, Italian, Continental]</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Cafe Delhi Heights</td>\n",
       "      <td>[Continental, North Indian, Beverages, Chinese...</td>\n",
       "      <td>Janpath, Central Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The G.T. Road</td>\n",
       "      <td>[North Indian]</td>\n",
       "      <td>M-Block,Connaught Place, Central Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Out Of The Box Courtyard</td>\n",
       "      <td>[North Indian, Mediterranean, Chinese, Italian]</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The Embassy</td>\n",
       "      <td>[North Indian, European, Fast Food, Italian, C...</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Imperfecto</td>\n",
       "      <td>[Asian, Finger Food, Continental, North Indian]</td>\n",
       "      <td>Janpath, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>My Bar Headquarters</td>\n",
       "      <td>[North Indian, Chinese]</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Dhaba Estd 1986 Delhi</td>\n",
       "      <td>[North Indian]</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sandoz</td>\n",
       "      <td>[North Indian, Continental]</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Wok in the Clouds</td>\n",
       "      <td>[Chinese, Thai, Continental, North Indian, Asian]</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Restaurant name  \\\n",
       "0                             Local   \n",
       "1                           Tamasha   \n",
       "2                  Ministry Of Beer   \n",
       "3                    Openhouse Cafe   \n",
       "4               Unplugged Courtyard   \n",
       "5                 The Junkyard Cafe   \n",
       "6                       Station Bar   \n",
       "7                           Berco's   \n",
       "8                               QBA   \n",
       "9                             Chido   \n",
       "10                      38 Barracks   \n",
       "11  Ardor 2.1 Restaurant and Lounge   \n",
       "12               Cafe Delhi Heights   \n",
       "13                    The G.T. Road   \n",
       "14         Out Of The Box Courtyard   \n",
       "15                      The Embassy   \n",
       "16                       Imperfecto   \n",
       "17              My Bar Headquarters   \n",
       "18            Dhaba Estd 1986 Delhi   \n",
       "19                           Sandoz   \n",
       "20                Wok in the Clouds   \n",
       "\n",
       "                                              Cuisine  \\\n",
       "0                  [North Indian, Asian, Continental]   \n",
       "1         [Continental, Asian, Italian, North Indian]   \n",
       "2        [North Indian, Continental, American, Asian]   \n",
       "3                      [North Indian, Asian, Italian]   \n",
       "4   [North Indian, Italian, Chinese, Turkish, Cont...   \n",
       "5     [North Indian, Continental, Chinese, Fast Food]   \n",
       "6         [Italian, Chinese, North Indian, Fast Food]   \n",
       "7                                     [Chinese, Thai]   \n",
       "8                [North Indian, Continental, Italian]   \n",
       "9   [North Indian, Italian, Continental, Asian, Fi...   \n",
       "10               [North Indian, Chinese, Continental]   \n",
       "11      [North Indian, Chinese, Italian, Continental]   \n",
       "12  [Continental, North Indian, Beverages, Chinese...   \n",
       "13                                     [North Indian]   \n",
       "14    [North Indian, Mediterranean, Chinese, Italian]   \n",
       "15  [North Indian, European, Fast Food, Italian, C...   \n",
       "16    [Asian, Finger Food, Continental, North Indian]   \n",
       "17                            [North Indian, Chinese]   \n",
       "18                                     [North Indian]   \n",
       "19                        [North Indian, Continental]   \n",
       "20  [Chinese, Thai, Continental, North Indian, Asian]   \n",
       "\n",
       "                                        Location Ratings  \\\n",
       "0   Scindia House,Connaught Place, Central Delhi       4   \n",
       "1                 Connaught Place, Central Delhi     4.2   \n",
       "2         M-Block,Connaught Place, Central Delhi       4   \n",
       "3                 Connaught Place, Central Delhi     4.1   \n",
       "4                 Connaught Place, Central Delhi       4   \n",
       "5                 Connaught Place, Central Delhi     4.1   \n",
       "6         F-Block,Connaught Place, Central Delhi       4   \n",
       "7                 Connaught Place, Central Delhi     4.3   \n",
       "8                 Connaught Place, Central Delhi     4.2   \n",
       "9                 Connaught Place, Central Delhi     4.2   \n",
       "10        M-Block,Connaught Place, Central Delhi     4.3   \n",
       "11                Connaught Place, Central Delhi     4.1   \n",
       "12                        Janpath, Central Delhi     4.3   \n",
       "13        M-Block,Connaught Place, Central Delhi     4.3   \n",
       "14                Connaught Place, Central Delhi     4.1   \n",
       "15                Connaught Place, Central Delhi     4.1   \n",
       "16                        Janpath, Central Delhi     4.1   \n",
       "17                Connaught Place, Central Delhi       4   \n",
       "18                Connaught Place, Central Delhi     4.1   \n",
       "19                Connaught Place, Central Delhi       4   \n",
       "20                Connaught Place, Central Delhi     4.3   \n",
       "\n",
       "                                            Image URL  \n",
       "0   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "9   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "10  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "11  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "12  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "13  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "14  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "15  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "16  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "17  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "18  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "19  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "20  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Columns Names\n",
    "col = ['Restaurant name', 'Cuisine', 'Location', 'Ratings', 'Image URL']\n",
    "\n",
    "#Data\n",
    "data = list(zip(Name, Cuisines, Location, Ratings, Img_Url))\n",
    "\n",
    "#Creating the Dataframe\n",
    "df = pd.DataFrame(data= data, columns = col)\n",
    "\n",
    "#Displaying the Dataframe\n",
    "(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
